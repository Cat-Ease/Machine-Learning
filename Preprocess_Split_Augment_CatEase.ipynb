{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING, SPLIT, AUGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                         # Untuk interaksi dengan os\n",
    "import matplotlib.pyplot as plt   # Untuk visualisasi data\n",
    "import matplotlib.image as mpimg  # Membaca dan memanipulasi gambar\n",
    "import tensorflow as tf           # Library untuk Machine Learning\n",
    "import random                     # untuk menghasilkan angka acak\n",
    "import shutil                     # Untuk interaksi dengan file dan dir "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLIT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direktori Dataset\n",
    "cat_disease_dir = \"/content/CAT SKIN DISEASE\"\n",
    "train_dir = \"/content/train_dir\"\n",
    "val_dir = \"/content/val_dir\"\n",
    "test_dir = \"/content/test_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat direktori\n",
    "os.makedirs(train_dir)\n",
    "os.makedirs(val_dir)\n",
    "os.makedirs(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio split dataset (Training:Validation:Test = 70:15:15)\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan pembagian dataset untuk setiap kelas yang ada\n",
    "for class_name in cat_disease_classes:\n",
    "  class_dir = os.path.join(cat_disease, class_name)\n",
    "  class_images = [img for img in os.listdir(class_dir) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "  num_images = len(class_images)\n",
    "\n",
    "  # Membuat subdirektori untuk setiap kelas dalam direktori train, val, dan test\n",
    "  train_class_dir = os.path.join(train_dir, class_name)\n",
    "  val_class_dir = os.path.join(val_dir, class_name)\n",
    "  test_class_dir = os.path.join(test_dir, class_name)\n",
    "\n",
    "  # Mengecek subdirektori yang dibuat, apabila belum terbuat maka dibuat\n",
    "  if not os.path.exists(train_class_dir):\n",
    "    os.makedirs(train_class_dir)\n",
    "  if not os.path.exists(val_class_dir):\n",
    "    os.makedirs(val_class_dir)\n",
    "  if not os.path.exists(test_class_dir):\n",
    "    os.makedirs(test_class_dir)\n",
    "\n",
    "  # Menentukan jumlah gambar untuk setiap set\n",
    "  num_train = int(num_images * train_ratio)\n",
    "  num_val = int(num_images * val_ratio)\n",
    "  num_test = num_images - num_train - num_val\n",
    "\n",
    "  # Mengacak urutan gambar\n",
    "  random.shuffle(class_images)\n",
    "\n",
    "  # Memindahkan gambar ke direktorinya masing masing\n",
    "  for i, image_name in enumerate(class_images):\n",
    "    image_path = os.path.join(class_dir, image_name)\n",
    "    if i < num_train:\n",
    "      shutil.copy(image_path, train_class_dir)\n",
    "    elif i < num_train + num_val:\n",
    "      shutil.copy(image_path, val_class_dir)\n",
    "    else:\n",
    "      shutil.copy(image_path, test_class_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan jumlah masing masing dataset setelah dibagikan\n",
    "print(\"\\nJumlah Dataset Setelah Pembagian:\")\n",
    "for dataset_dir in [train_dir, val_dir, test_dir]:\n",
    "  if dataset_dir == train_dir:\n",
    "    print(\"Training Dataset:\")\n",
    "  elif dataset_dir == val_dir:\n",
    "    print(\"Validation Dataset:\")\n",
    "  else:\n",
    "    print(\"Testing Dataset:\")\n",
    "  for class_name in cat_disease_classes:\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "    num_images = len(os.listdir(class_dir))\n",
    "    print(f\"  {class_name}: {num_images} gambar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat Traininng Dataset\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir, \n",
    "                                                      image_size=(120, 120),\n",
    "                                                      batch_size=32,\n",
    "                                                      label_mode='categorical') # Karena class lebih dari 2\n",
    "\n",
    "# Membuat Validation Dataset\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(val_dir,  \n",
    "                                                    image_size=(120, 120),\n",
    "                                                    batch_size=32,\n",
    "                                                    label_mode='categorical') # Karena class lebih dari 2\n",
    "\n",
    "# Optimisasi Dataset\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "PREFETCH_BUFFER_SIZE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset_fin = (train_dataset\n",
    "                     .cache()\n",
    "                     .shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "                     .prefetch(PREFETCH_BUFFER_SIZE))\n",
    "\n",
    "val_dataset_fin = (val_dataset\n",
    "                     .cache()\n",
    "                     .shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "                     .prefetch(PREFETCH_BUFFER_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUGMENTASI GAMBAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi augmentasi gambar\n",
    "def augment_image(image):\n",
    "    image_augmentation = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(120,120,3)),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomWidth(0.2),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomHeight(0.2)])\n",
    "    \n",
    "    return image_augmentation(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampilkan contoh gambar yang telah di augmentasi\n",
    "def display_augmented_images(images, num_samples=5):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(num_samples):\n",
    "        img = random.choice(images)  \n",
    "        augmented_img = augment_image(img)  \n",
    "        plt.subplot(1, num_samples, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(augmented_img)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
